{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_feather(\"../data/data.feather\")\n",
    "test_items_df = pd.read_csv(\"../data/test_items.csv\",index_col=0)\n",
    "question_data = pd.read_csv(\"../data/question_data.csv\", sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_qs = [item for item in test_items_df.index if item in raw_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = raw_df.drop(columns=test_item_qs)\n",
    "q_df = q_df.filter(regex=r'^q\\d+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the lowest response q's\n",
    "N_DROP = 2000\n",
    "low_response = [col for col in question_data.sort_values('N').iloc[:N_DROP].index if col in q_df.columns]\n",
    "q_df = q_df.drop(columns=low_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by number of categories for easier manipulation later\n",
    "sorted_num_levels = q_df.apply(lambda x: len(x.cat.categories)).sort_values()\n",
    "q_df = q_df[sorted_num_levels.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border indices where level count changes: [252, 392]\n",
      "Levels at borders: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique levels per column\n",
    "num_levels = q_df.nunique()\n",
    "\n",
    "# Sort columns by unique levels\n",
    "sorted_num_levels = num_levels.sort_values()\n",
    "\n",
    "# Find the indices where the level count changes\n",
    "level_counts = sorted_num_levels.values\n",
    "diff = level_counts[1:] != level_counts[:-1]\n",
    "border_indices = list(diff.nonzero()[0] + 1)  # +1 because diff is between elements\n",
    "\n",
    "# For example, print the borders and corresponding levels\n",
    "print(\"Border indices where level count changes:\", border_indices)\n",
    "print(\"Levels at borders:\", level_counts[border_indices])\n",
    "\n",
    "# You can use these indices to split the sorted columns into dfs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "non_nan = ~q_df.isna()\n",
    "non_nan_indices = np.flatnonzero(non_nan.values)\n",
    "\n",
    "np.random.seed(0)\n",
    "TEST_SIZE = 0.2\n",
    "test_size = int(len(non_nan_indices) * TEST_SIZE)\n",
    "test_mask_flat = np.random.choice(non_nan_indices, size=test_size, replace=False)\n",
    "\n",
    "test_mask = np.zeros_like(q_df.values, dtype=bool)\n",
    "test_mask.flat[test_mask_flat] = True\n",
    "\n",
    "# mask some cells that serve as our test set\n",
    "df_masked = q_df.mask(test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse_output=True, handle_unknown='ignore'), q_df.columns),\n",
    "    ],\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "def transform_and_drop(df):\n",
    "    X = preprocessor.fit_transform(df)\n",
    "\n",
    "    # the sklearn onehot encoder doesn't have an option to not encode nans\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    cols_to_keep = [i for i, name in enumerate(feature_names) if not name.endswith('_nan')]\n",
    "    X = X[:, cols_to_keep]\n",
    "    return X\n",
    "\n",
    "X_combined = transform_and_drop(df_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Original mask (shape: n_users x n_original_questions)\n",
    "\n",
    "# convert the original mask to a mask over the onehots\n",
    "def expand_mask(mask):\n",
    "    mask_expanded = []\n",
    "    for col_idx, col in enumerate(q_df.columns):\n",
    "        n_categories = len(q_df[col].cat.categories)\n",
    "        # Repeat mask along a new axis (shape: n_users x n_categories)\n",
    "        mask_repeated = np.repeat(mask[:, col_idx][:, np.newaxis], n_categories, axis=1)\n",
    "        mask_expanded.append(mask_repeated)\n",
    "        # sanity check\n",
    "        assert mask_repeated.shape[0] == 68371\n",
    "\n",
    "    # Stack horizontally (shape: n_users x n_encoded_features)\n",
    "    mask_expanded = np.hstack(mask_expanded)\n",
    "    return mask_expanded\n",
    "\n",
    "# Convert to sparse matrix (if X_combined is sparse)\n",
    "test_mask_expanded = expand_mask(test_mask)\n",
    "test_mask_sparse = sparse.csr_matrix(test_mask_expanded)\n",
    "\n",
    "original_mask = expand_mask(non_nan.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68371, 1660) (68371, 1660)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "print(test_mask_sparse.shape, X_combined.shape)\n",
    "X_combined[test_mask_sparse.nonzero()].any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaned, ready for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_q_answered = df_masked.notna().mean()\n",
    "pr_user_answered = df_masked.notna().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()\n",
    "kept_features = [item[8:].split('_') for item in feature_names if not item.endswith('_nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 q170849 No. Why spoil the mystery?\n",
      "pr(user answers)= 0.3177083333333333\n",
      "pr(question gets answered)= 0.46557751093299793\n",
      "pr(option i selected | question K gets answered)= 0.6508859009801458\n",
      "take the prodcut of these\n"
     ]
    }
   ],
   "source": [
    "# demonstration of how the naive imputation model works\n",
    "\n",
    "for user, feature in zip(*test_mask_sparse.nonzero()):\n",
    "    question, option = kept_features[feature]\n",
    "    print(user, question, option)\n",
    "    print(\"pr(user answers)=\", pr_user_answered[user])\n",
    "    print(\"pr(question gets answered)=\", pr_q_answered[question])\n",
    "    print(\"pr(option i selected | question K gets answered)=\", df_masked[question].value_counts(normalize=True)[option])\n",
    "    print(\"take the prodcut of these\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array([q for q, o in kept_features])\n",
    "options   = np.array([o for q, o in kept_features])\n",
    "\n",
    "option_probs = {\n",
    "    q: df_masked[q].value_counts(normalize=True).reindex(q_df[q].cat.categories, fill_value=0)\n",
    "    for q in q_df.columns\n",
    "}\n",
    "option_probs_df = pd.DataFrame(option_probs).T  # index: question, columns: option. super redundant but helps vectorize the operations below\n",
    "\n",
    "users_idx, features_idx = test_mask_sparse.nonzero()\n",
    "\n",
    "q_for_masked = questions[features_idx]\n",
    "o_for_masked = options[features_idx]\n",
    "\n",
    "pr_user_vals = pr_user_answered.values[users_idx]\n",
    "pr_q_vals    = pr_q_answered[q_for_masked].values\n",
    "pr_option_vals = option_probs_df.values[\n",
    "    option_probs_df.index.get_indexer(q_for_masked),\n",
    "    option_probs_df.columns.get_indexer(o_for_masked)\n",
    "]\n",
    "\n",
    "# Vectorized naive bayes\n",
    "naive_imputed_values = pr_user_vals * pr_q_vals * pr_option_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare hidden test values to real values\n",
    "X_not_masked = transform_and_drop(q_df)\n",
    "\n",
    "# check:\n",
    "X_not_masked.shape == X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27301140033485116"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_naive = (np.asarray(X_not_masked[test_mask_sparse] - naive_imputed_values).ravel()**2).mean()\n",
    "mse_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3185008577329666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the one that Yoram explained to me, but I think the one above makes more sense.\n",
    "\n",
    "row_mean = X_combined.mean(axis=1).ravel()\n",
    "col_mean = X_combined.mean(axis=0).ravel()\n",
    "\n",
    "naive_imputation2 = np.asarray(row_mean).ravel()[users_idx] * np.asarray(col_mean).ravel()[features_idx]\n",
    "\n",
    "mse_naive2 = (np.asarray(X_not_masked[test_mask_sparse] - naive_imputation2).ravel()**2).mean()\n",
    "mse_naive2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing values randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3334107803502178"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random\n",
    "mse_random = (np.asarray(X_not_masked[test_mask_sparse] - np.random.uniform(size=naive_imputed_values.shape)).ravel() **2).mean()\n",
    "mse_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.346698171916797"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute as all zeros\n",
    "mse_zero = (np.asarray(X_not_masked[test_mask_sparse] - np.zeros_like(naive_imputed_values)).ravel() **2).mean()\n",
    "mse_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing as modal answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(series):\n",
    "    return series.mode().iloc[0]\n",
    "\n",
    "df_modal_imputed = df_masked.apply(lambda col: col.fillna(get_mode(col)))\n",
    "X_modal = transform_and_drop(df_modal_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.254023334054584"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_modal = (np.asarray(X_not_masked[test_mask_sparse] - X_modal[test_mask_sparse]).ravel() **2).mean()\n",
    "mse_modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### low rank approximation method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3477330505847931\n",
      "Epoch 1, Loss: 0.32999297976493835\n",
      "Epoch 2, Loss: 0.3125763535499573\n",
      "Epoch 3, Loss: 0.295748770236969\n",
      "Epoch 4, Loss: 0.2797464430332184\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert sparse matrices to PyTorch tensors\n",
    "X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.bool)\n",
    "train_mask_tensor = torch.tensor(original_mask, dtype=torch.bool) & ~test_mask_tensor\n",
    "\n",
    "# Hyperparameters\n",
    "rank = 10  # Rank of the approximation (adjust as needed)\n",
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "# Initialize low-rank matrices B and C\n",
    "n_users, n_features = X_combined.shape\n",
    "B = torch.randn(n_users, rank, requires_grad=True)\n",
    "C = torch.randn(rank, n_features, requires_grad=True)\n",
    "X_hat = torch.mm(B, C)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([B, C], lr=learning_rate)\n",
    "\n",
    "# @torch.compile\n",
    "def split_and_softmax(X):\n",
    "    split_sizes = [border_indices[0]] + \\\n",
    "                [border_indices[i+1] - border_indices[i] for i in range(len(border_indices)-1)] + \\\n",
    "                [q_df.shape[1] - border_indices[-1]]\n",
    "\n",
    "    split_sizes = [item * (i+2) for i, item in enumerate(split_sizes)]\n",
    "    split_tensors = torch.split(X, split_sizes, dim=1)\n",
    "\n",
    "    processed_tensors = []\n",
    "    for i, tensor in enumerate(split_tensors):\n",
    "        options_per_question = 2 + i  # 2 for first split, 3 for second, 4 for third\n",
    "        n_questions = tensor.shape[1] // options_per_question\n",
    "        \n",
    "        # Reshape to (n_users, n_questions, options_per_question)\n",
    "        reshaped = tensor.view(-1, n_questions, options_per_question)\n",
    "        \n",
    "        # Apply softmax along the last dimension\n",
    "        softmaxed = F.softmax(reshaped, dim=-1)\n",
    "        processed_tensors.append(softmaxed)\n",
    "    \n",
    "    flattened_tensors = [tensor.view(tensor.shape[0], -1) for tensor in processed_tensors]\n",
    "    X_softmaxed = torch.cat(flattened_tensors, dim=1)\n",
    "    return X_softmaxed\n",
    "\n",
    "# Training loop\n",
    "# @torch.compile\n",
    "def train_loop():\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Reconstruct X_hat = B @ C\n",
    "        X_hat = torch.mm(B, C)\n",
    "        X_hat = split_and_softmax(X_hat)\n",
    "\n",
    "        # Compute loss only on observed entries (not masked for testing)\n",
    "        loss = torch.mean((X_hat[train_mask_tensor] - X_combined_tensor[train_mask_tensor]) ** 2)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    return X_hat\n",
    "\n",
    "X_hat = train_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-rank MSE: 0.2890086825278953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After training, use X_hat to impute missing values\n",
    "X_imputed = X_hat.detach().numpy()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "imputed_test_values = X_imputed[test_mask_sparse.toarray()]\n",
    "\n",
    "mse_low_rank = ((test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Low-rank MSE: {mse_low_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, ...,  True,  True,  True],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4497, 0.5503, 0.4998,  ..., 0.2506, 0.2327, 0.2524],\n",
       "        [0.5028, 0.4972, 0.5000,  ..., 0.2499, 0.2510, 0.2499],\n",
       "        [0.2171, 0.7829, 0.4984,  ..., 0.2456, 0.1531, 0.2567],\n",
       "        ...,\n",
       "        [0.7103, 0.2897, 0.5011,  ..., 0.2409, 0.3353, 0.2336],\n",
       "        [0.8015, 0.1985, 0.5017,  ..., 0.2316, 0.3873, 0.2208],\n",
       "        [0.9088, 0.0912, 0.5028,  ..., 0.2082, 0.4858, 0.1924]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
