{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_feather(\"../data/data.feather\")\n",
    "test_items_df = pd.read_csv(\"../data/test_items.csv\",index_col=0)\n",
    "question_data = pd.read_csv(\"../data/question_data.csv\", sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_weights = pd.read_csv('../outputs/question_weights.csv', index_col=0)\n",
    "q_weights = question_weights.scores.to_list()\n",
    "len(q_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_qs = [item for item in test_items_df.index if item in raw_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = raw_df.drop(columns=test_item_qs)\n",
    "q_df = q_df.filter(regex=r'^q\\d+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the lowest response q's\n",
    "N_DROP = 2000\n",
    "low_response = [col for col in question_data.sort_values('N').iloc[:N_DROP].index if col in q_df.columns]\n",
    "q_df = q_df.drop(columns=low_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by number of categories for easier manipulation later\n",
    "sorted_num_levels = q_df.apply(lambda x: len(x.cat.categories)).sort_values()\n",
    "q_df = q_df[sorted_num_levels.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data.loc[q_df.columns].to_csv('../outputs/filtered_qs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>option_1</th>\n",
       "      <th>option_2</th>\n",
       "      <th>option_3</th>\n",
       "      <th>option_4</th>\n",
       "      <th>N</th>\n",
       "      <th>Type</th>\n",
       "      <th>Order</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q19365</th>\n",
       "      <td>If you meet someone and they are everything yo...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25296</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q47635</th>\n",
       "      <td>Imagine you have a partner who is able to prov...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>No.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23885</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>preference; descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q165644</th>\n",
       "      <td>What's worse on a first date?</td>\n",
       "      <td>No physical attraction</td>\n",
       "      <td>Nothing to talk about</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40161</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>religion/superstition; descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q158</th>\n",
       "      <td>Are you an aspiring actor/artist/writer or oth...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40052</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q15744</th>\n",
       "      <td>Are you a pet person?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25704</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q30723</th>\n",
       "      <td>Which is the greatest compliment you could rec...</td>\n",
       "      <td>That you are beautiful/sexy/hot</td>\n",
       "      <td>That you are intelligent</td>\n",
       "      <td>That you are talented</td>\n",
       "      <td>That you are extremely fun to be with</td>\n",
       "      <td>25230</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>preference; descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q21488</th>\n",
       "      <td>Do you pick up after yourself? Be honest.</td>\n",
       "      <td>Always.</td>\n",
       "      <td>Yeah, when I have the time.</td>\n",
       "      <td>No, I live in filth.</td>\n",
       "      <td>No, my mom/roommate/partner mostly does it for...</td>\n",
       "      <td>30108</td>\n",
       "      <td>O</td>\n",
       "      <td>(3, 4), 2, 1</td>\n",
       "      <td>descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q274</th>\n",
       "      <td>What's the highest level of education you've c...</td>\n",
       "      <td>Graduate School</td>\n",
       "      <td>College</td>\n",
       "      <td>High School</td>\n",
       "      <td>Junior High</td>\n",
       "      <td>31706</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>descriptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q218</th>\n",
       "      <td>Should prostitution be legal?</td>\n",
       "      <td>Yes, absolutely</td>\n",
       "      <td>Yes, only if it were regulated</td>\n",
       "      <td>I don't think so</td>\n",
       "      <td>ABSOLUTELY NOT</td>\n",
       "      <td>25694</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politics; religion/superstition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q265</th>\n",
       "      <td>Who do you think was smartest on this list?</td>\n",
       "      <td>Einstein</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Mozart</td>\n",
       "      <td>Jesus</td>\n",
       "      <td>29398</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "q19365   If you meet someone and they are everything yo...   \n",
       "q47635   Imagine you have a partner who is able to prov...   \n",
       "q165644                      What's worse on a first date?   \n",
       "q158     Are you an aspiring actor/artist/writer or oth...   \n",
       "q15744                               Are you a pet person?   \n",
       "...                                                    ...   \n",
       "q30723   Which is the greatest compliment you could rec...   \n",
       "q21488           Do you pick up after yourself? Be honest.   \n",
       "q274     What's the highest level of education you've c...   \n",
       "q218                         Should prostitution be legal?   \n",
       "q265           Who do you think was smartest on this list?   \n",
       "\n",
       "                                option_1                        option_2  \\\n",
       "q19365                               Yes                              No   \n",
       "q47635                              Yes.                             No.   \n",
       "q165644           No physical attraction           Nothing to talk about   \n",
       "q158                                 Yes                              No   \n",
       "q15744                               Yes                              No   \n",
       "...                                  ...                             ...   \n",
       "q30723   That you are beautiful/sexy/hot        That you are intelligent   \n",
       "q21488                           Always.     Yeah, when I have the time.   \n",
       "q274                     Graduate School                         College   \n",
       "q218                     Yes, absolutely  Yes, only if it were regulated   \n",
       "q265                            Einstein                     Shakespeare   \n",
       "\n",
       "                      option_3  \\\n",
       "q19365                     NaN   \n",
       "q47635                     NaN   \n",
       "q165644                    NaN   \n",
       "q158                       NaN   \n",
       "q15744                     NaN   \n",
       "...                        ...   \n",
       "q30723   That you are talented   \n",
       "q21488    No, I live in filth.   \n",
       "q274               High School   \n",
       "q218          I don't think so   \n",
       "q265                    Mozart   \n",
       "\n",
       "                                                  option_4      N Type  \\\n",
       "q19365                                                 NaN  25296    O   \n",
       "q47635                                                 NaN  23885    O   \n",
       "q165644                                                NaN  40161    O   \n",
       "q158                                                   NaN  40052    O   \n",
       "q15744                                                 NaN  25704    O   \n",
       "...                                                    ...    ...  ...   \n",
       "q30723               That you are extremely fun to be with  25230    N   \n",
       "q21488   No, my mom/roommate/partner mostly does it for...  30108    O   \n",
       "q274                                           Junior High  31706    O   \n",
       "q218                                        ABSOLUTELY NOT  25694    O   \n",
       "q265                                                 Jesus  29398    N   \n",
       "\n",
       "                Order                            Keywords  \n",
       "q19365            NaN                          preference  \n",
       "q47635            NaN             preference; descriptive  \n",
       "q165644           NaN  religion/superstition; descriptive  \n",
       "q158              NaN                         descriptive  \n",
       "q15744            NaN                         descriptive  \n",
       "...               ...                                 ...  \n",
       "q30723            NaN             preference; descriptive  \n",
       "q21488   (3, 4), 2, 1                         descriptive  \n",
       "q274              NaN                         descriptive  \n",
       "q218              NaN     politics; religion/superstition  \n",
       "q265              NaN                             opinion  \n",
       "\n",
       "[576 rows x 9 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data.loc[q_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q19365</th>\n",
       "      <th>q47635</th>\n",
       "      <th>q165644</th>\n",
       "      <th>q158</th>\n",
       "      <th>q15744</th>\n",
       "      <th>q155</th>\n",
       "      <th>q15478</th>\n",
       "      <th>q47764</th>\n",
       "      <th>q19737</th>\n",
       "      <th>q171</th>\n",
       "      <th>...</th>\n",
       "      <th>q33602</th>\n",
       "      <th>q34517</th>\n",
       "      <th>q35355</th>\n",
       "      <th>q28754</th>\n",
       "      <th>q30207</th>\n",
       "      <th>q30723</th>\n",
       "      <th>q21488</th>\n",
       "      <th>q274</th>\n",
       "      <th>q218</th>\n",
       "      <th>q265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nothing to talk about</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm open, but I don't get too crazy.</td>\n",
       "      <td>At least 2 years</td>\n",
       "      <td>No, it's fine.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Nothing to talk about</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes, almost always</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No, it's underrated.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68367</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68368</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68369</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68371 rows Ã— 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      q19365 q47635                q165644 q158 q15744 q155 q15478 q47764  \\\n",
       "0        NaN    NaN  Nothing to talk about  NaN    Yes  NaN    NaN    NaN   \n",
       "1        NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "2        Yes   Yes.  Nothing to talk about  NaN    NaN  NaN    NaN   Yes.   \n",
       "3        NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "4        NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "...      ...    ...                    ...  ...    ...  ...    ...    ...   \n",
       "68366    NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "68367    NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "68368    NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "68369    NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "68370    NaN    NaN                    NaN  NaN    NaN  NaN    NaN    NaN   \n",
       "\n",
       "      q19737 q171  ...              q33602 q34517  \\\n",
       "0        Yes  NaN  ...                 NaN    NaN   \n",
       "1        NaN  NaN  ...                 NaN    NaN   \n",
       "2        Yes  NaN  ...  Yes, almost always    NaN   \n",
       "3        NaN  NaN  ...                 NaN    NaN   \n",
       "4        NaN  NaN  ...                 NaN    NaN   \n",
       "...      ...  ...  ...                 ...    ...   \n",
       "68366    NaN  NaN  ...                 NaN    NaN   \n",
       "68367    NaN  NaN  ...                 NaN    NaN   \n",
       "68368    NaN  NaN  ...                 NaN    NaN   \n",
       "68369    NaN  NaN  ...                 NaN    NaN   \n",
       "68370    NaN  NaN  ...                 NaN    NaN   \n",
       "\n",
       "                                     q35355            q28754  \\\n",
       "0      I'm open, but I don't get too crazy.  At least 2 years   \n",
       "1                                       NaN               NaN   \n",
       "2                                       NaN               NaN   \n",
       "3                                       NaN               NaN   \n",
       "4                                       NaN               NaN   \n",
       "...                                     ...               ...   \n",
       "68366                                   NaN               NaN   \n",
       "68367                                   NaN               NaN   \n",
       "68368                                   NaN               NaN   \n",
       "68369                                   NaN               NaN   \n",
       "68370                                   NaN               NaN   \n",
       "\n",
       "                     q30207 q30723 q21488             q274 q218 q265  \n",
       "0            No, it's fine.    NaN    NaN  Graduate School  NaN  NaN  \n",
       "1                       NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "2      No, it's underrated.    NaN    NaN          College  NaN  NaN  \n",
       "3                       NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "4                       NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "...                     ...    ...    ...              ...  ...  ...  \n",
       "68366                   NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "68367                   NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "68368                   NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "68369                   NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "68370                   NaN    NaN    NaN              NaN  NaN  NaN  \n",
       "\n",
       "[68371 rows x 576 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border indices where level count changes: [np.int64(252), np.int64(392)]\n",
      "Levels at borders: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique levels per column\n",
    "num_levels = q_df.nunique()\n",
    "\n",
    "# Sort columns by unique levels\n",
    "sorted_num_levels = num_levels.sort_values()\n",
    "\n",
    "# Find the indices where the level count changes\n",
    "level_counts = sorted_num_levels.values\n",
    "diff = level_counts[1:] != level_counts[:-1]\n",
    "border_indices = list(diff.nonzero()[0] + 1)  # +1 because diff is between elements\n",
    "\n",
    "# For example, print the borders and corresponding levels\n",
    "print(\"Border indices where level count changes:\", border_indices)\n",
    "print(\"Levels at borders:\", level_counts[border_indices])\n",
    "\n",
    "# You can use these indices to split the sorted columns into dfs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "non_nan = ~q_df.isna()\n",
    "non_nan_indices = np.flatnonzero(non_nan.values)\n",
    "\n",
    "np.random.seed(0)\n",
    "TEST_SIZE = 0.2\n",
    "test_size = int(len(non_nan_indices) * TEST_SIZE)\n",
    "test_mask_flat = np.random.choice(non_nan_indices, size=test_size, replace=False)\n",
    "\n",
    "test_mask = np.zeros_like(q_df.values, dtype=bool)\n",
    "test_mask.flat[test_mask_flat] = True\n",
    "\n",
    "# mask some cells that serve as our test set\n",
    "df_masked = q_df.mask(test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68371, 576)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse_output=True, handle_unknown='ignore'), q_df.columns),\n",
    "    ],\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "def transform_and_drop(df):\n",
    "    X = preprocessor.fit_transform(df)\n",
    "\n",
    "    # the sklearn onehot encoder doesn't have an option to not encode nans\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    cols_to_keep = [i for i, name in enumerate(feature_names) if not name.endswith('_nan')]\n",
    "    X = X[:, cols_to_keep]\n",
    "    return X\n",
    "\n",
    "X_combined = transform_and_drop(df_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Original mask (shape: n_users x n_original_questions)\n",
    "\n",
    "# convert the original mask to a mask over the onehots\n",
    "def expand_mask(mask):\n",
    "    mask_expanded = []\n",
    "    for col_idx, col in enumerate(q_df.columns):\n",
    "        n_categories = len(q_df[col].cat.categories)\n",
    "        # Repeat mask along a new axis (shape: n_users x n_categories)\n",
    "        mask_repeated = np.repeat(mask[:, col_idx][:, np.newaxis], n_categories, axis=1)\n",
    "        mask_expanded.append(mask_repeated)\n",
    "        # sanity check\n",
    "        assert mask_repeated.shape[0] == 68371\n",
    "\n",
    "    # Stack horizontally (shape: n_users x n_encoded_features)\n",
    "    mask_expanded = np.hstack(mask_expanded)\n",
    "    return mask_expanded\n",
    "\n",
    "# Convert to sparse matrix (if X_combined is sparse)\n",
    "test_mask_expanded = expand_mask(test_mask)\n",
    "test_mask_sparse = sparse.csr_matrix(test_mask_expanded)\n",
    "\n",
    "original_mask = expand_mask(non_nan.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68371, 1660) (68371, 1660)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "print(test_mask_sparse.shape, X_combined.shape)\n",
    "X_combined[test_mask_sparse.nonzero()].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10444820,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand loss weights:\n",
    "\n",
    "def expand_loss_weights(weights):\n",
    "    weights_expanded = []\n",
    "    for col_idx, col in enumerate(q_df.columns):\n",
    "        n_categories = len(q_df[col].cat.categories)\n",
    "        # Repeat mask along a new axis (shape: n_users x n_categories)\n",
    "        weights_expanded += ([weights[col_idx]] * n_categories)\n",
    "        # sanity check\n",
    "    assert len(weights_expanded) == 1660\n",
    "    return weights_expanded\n",
    "\n",
    "weights_expanded = expand_loss_weights(q_weights)\n",
    "_, test_mask_qs = np.nonzero(test_mask_expanded)\n",
    "loss_weights_test = np.array(weights_expanded)[test_mask_qs]\n",
    "loss_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaned, ready for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_q_answered = df_masked.notna().mean()\n",
    "pr_user_answered = df_masked.notna().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()\n",
    "kept_features = [item[8:].split('_') for item in feature_names if not item.endswith('_nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 q44639 No\n",
      "pr(user answers)= 0.3177083333333333\n",
      "pr(question gets answered)= 0.6423483640724869\n",
      "pr(option i selected | question K gets answered)= 0.38171137119176646\n",
      "take the prodcut of these\n"
     ]
    }
   ],
   "source": [
    "# demonstration of how the naive imputation model works\n",
    "\n",
    "for user, feature in zip(*test_mask_sparse.nonzero()):\n",
    "    question, option = kept_features[feature]\n",
    "    print(user, question, option)\n",
    "    print(\"pr(user answers)=\", pr_user_answered[user])\n",
    "    print(\"pr(question gets answered)=\", pr_q_answered[question])\n",
    "    print(\"pr(option i selected | question K gets answered)=\", df_masked[question].value_counts(normalize=True)[option])\n",
    "    print(\"take the prodcut of these\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array([q for q, o in kept_features])\n",
    "options   = np.array([o for q, o in kept_features])\n",
    "\n",
    "option_probs = {\n",
    "    q: df_masked[q].value_counts(normalize=True).reindex(q_df[q].cat.categories, fill_value=0)\n",
    "    for q in q_df.columns\n",
    "}\n",
    "option_probs_df = pd.DataFrame(option_probs).T  # index: question, columns: option. super redundant but helps vectorize the operations below\n",
    "\n",
    "users_idx, features_idx = test_mask_sparse.nonzero()\n",
    "\n",
    "q_for_masked = questions[features_idx]\n",
    "o_for_masked = options[features_idx]\n",
    "\n",
    "pr_user_vals = pr_user_answered.values[users_idx]\n",
    "pr_q_vals    = pr_q_answered[q_for_masked].values\n",
    "pr_option_vals = option_probs_df.values[\n",
    "    option_probs_df.index.get_indexer(q_for_masked),\n",
    "    option_probs_df.columns.get_indexer(o_for_masked)\n",
    "]\n",
    "\n",
    "# Vectorized naive bayes\n",
    "naive_imputed_values = pr_user_vals * pr_q_vals * pr_option_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare hidden test values to real values\n",
    "X_not_masked = transform_and_drop(q_df)\n",
    "\n",
    "# check:\n",
    "X_not_masked.shape == X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10444820,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.asarray(X_not_masked[test_mask_sparse] - naive_imputed_values).ravel()**2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.27249386668583225)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_naive = np.average(np.asarray(X_not_masked[test_mask_sparse] - naive_imputed_values).ravel()**2, weights=loss_weights)\n",
    "mse_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.31765224077267906)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the one that Yoram explained to me, but I think the one above makes more sense.\n",
    "\n",
    "row_mean = X_combined.mean(axis=1).ravel()\n",
    "col_mean = X_combined.mean(axis=0).ravel()\n",
    "\n",
    "naive_imputation2 = np.asarray(row_mean).ravel()[users_idx] * np.asarray(col_mean).ravel()[features_idx]\n",
    "\n",
    "mse_naive2 = np.average(np.asarray(X_not_masked[test_mask_sparse] - naive_imputation2).ravel()**2, weights=loss_weights)\n",
    "mse_naive2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing values randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.33313321292160564)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random\n",
    "mse_random = np.average(np.asarray(X_not_masked[test_mask_sparse] - np.random.uniform(size=naive_imputed_values.shape)).ravel() **2, weights=loss_weights)\n",
    "mse_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22617873756601115)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute as as constant, mean of test data:\n",
    "\n",
    "train_data = X_not_masked[original_mask & ~test_mask_sparse.toarray()]\n",
    "mean_val = train_data.mean()\n",
    "\n",
    "mse_constant = np.average(np.asarray(X_not_masked[test_mask_sparse] - (np.zeros_like(naive_imputed_values) + mean_val)).ravel() **2, weights=loss_weights)\n",
    "mse_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing as modal answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(series):\n",
    "    return series.mode().iloc[0]\n",
    "\n",
    "df_modal_imputed = df_masked.apply(lambda col: col.fillna(get_mode(col)))\n",
    "X_modal = transform_and_drop(df_modal_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2552871884444088)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_modal = np.average(np.asarray(X_not_masked[test_mask_sparse] - X_modal[test_mask_sparse]).ravel() **2, weights=loss_weights)\n",
    "mse_modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### low rank approximation method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def torch_avg(tensor, weights):\n",
    "    assert tensor.shape == weights.shape\n",
    "    return torch.sum(tensor * weights) / torch.sum(weights)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrices to PyTorch tensors\n",
    "X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32).to(device)\n",
    "test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.bool).to(device)\n",
    "train_mask_tensor = torch.tensor(original_mask, dtype=torch.bool).to(device) & ~test_mask_tensor\n",
    "\n",
    "train_mask_qs = torch.nonzero(train_mask_tensor)[:,1]\n",
    "loss_weights_train = torch.tensor(weights_expanded)[train_mask_qs.cpu()].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3157169818878174\n",
      "Epoch 1, Loss: 0.2808621823787689\n",
      "Epoch 2, Loss: 0.25307703018188477\n",
      "Epoch 3, Loss: 0.23464952409267426\n",
      "Epoch 4, Loss: 0.22256280481815338\n",
      "Epoch 5, Loss: 0.21221695840358734\n",
      "Epoch 6, Loss: 0.20023085176944733\n",
      "Epoch 7, Loss: 0.18765713274478912\n",
      "Epoch 8, Loss: 0.17891374230384827\n",
      "Epoch 9, Loss: 0.1747337132692337\n",
      "Epoch 10, Loss: 0.17210820317268372\n",
      "Epoch 11, Loss: 0.16962610185146332\n",
      "Epoch 12, Loss: 0.16751839220523834\n",
      "Epoch 13, Loss: 0.16572529077529907\n",
      "Epoch 14, Loss: 0.16383735835552216\n",
      "Epoch 15, Loss: 0.16209885478019714\n",
      "Epoch 16, Loss: 0.16056764125823975\n",
      "Epoch 17, Loss: 0.15906058251857758\n",
      "Epoch 18, Loss: 0.1577584147453308\n",
      "Epoch 19, Loss: 0.15664654970169067\n",
      "Epoch 20, Loss: 0.1555720418691635\n",
      "Epoch 21, Loss: 0.15451526641845703\n",
      "Epoch 22, Loss: 0.15351015329360962\n",
      "Epoch 23, Loss: 0.15251047909259796\n",
      "Epoch 24, Loss: 0.1515348106622696\n",
      "Epoch 25, Loss: 0.15062464773654938\n",
      "Epoch 26, Loss: 0.14973215758800507\n",
      "Epoch 27, Loss: 0.14886388182640076\n",
      "Epoch 28, Loss: 0.1480148434638977\n",
      "Epoch 29, Loss: 0.14724887907505035\n",
      "Epoch 30, Loss: 0.14655131101608276\n",
      "Epoch 31, Loss: 0.14588043093681335\n",
      "Epoch 32, Loss: 0.14528292417526245\n",
      "Epoch 33, Loss: 0.1447366327047348\n",
      "Epoch 34, Loss: 0.14420731365680695\n",
      "Epoch 35, Loss: 0.1437274068593979\n",
      "Epoch 36, Loss: 0.14330875873565674\n",
      "Epoch 37, Loss: 0.1429164856672287\n",
      "Epoch 38, Loss: 0.14255793392658234\n",
      "Epoch 39, Loss: 0.14225567877292633\n",
      "Epoch 40, Loss: 0.1419709175825119\n",
      "Epoch 41, Loss: 0.1416769027709961\n",
      "Epoch 42, Loss: 0.14141525328159332\n",
      "Epoch 43, Loss: 0.1412072330713272\n",
      "Epoch 44, Loss: 0.14102599024772644\n",
      "Epoch 45, Loss: 0.14085233211517334\n",
      "Epoch 46, Loss: 0.14068278670310974\n",
      "Epoch 47, Loss: 0.1405104547739029\n",
      "Epoch 48, Loss: 0.14033938944339752\n",
      "Epoch 49, Loss: 0.14018094539642334\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "rank = 5  # Rank of the approximation (adjust as needed)\n",
    "learning_rate = 0.2\n",
    "epochs = 50\n",
    "\n",
    "# Initialize low-rank matrices B and C\n",
    "n_users, n_features = X_combined.shape\n",
    "B = torch.randn(n_users, rank, requires_grad=True, device=device)\n",
    "C = torch.randn(rank, n_features, requires_grad=True, device=device)\n",
    "X_hat = torch.mm(B, C)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([B, C], lr=learning_rate)\n",
    "\n",
    "@torch.compile\n",
    "def split_and_softmax(X):\n",
    "    split_sizes = [border_indices[0]] + \\\n",
    "                [border_indices[i+1] - border_indices[i] for i in range(len(border_indices)-1)] + \\\n",
    "                [q_df.shape[1] - border_indices[-1]]\n",
    "\n",
    "    split_sizes = [item * (i+2) for i, item in enumerate(split_sizes)]\n",
    "    split_tensors = torch.split(X, split_sizes, dim=1)\n",
    "\n",
    "    processed_tensors = []\n",
    "    for i, tensor in enumerate(split_tensors):\n",
    "        options_per_question = 2 + i  # 2 for first split, 3 for second, 4 for third\n",
    "        n_questions = tensor.shape[1] // options_per_question\n",
    "        \n",
    "        # Reshape to (n_users, n_questions, options_per_question)\n",
    "        reshaped = tensor.view(-1, n_questions, options_per_question)\n",
    "        \n",
    "        # Apply softmax along the last dimension\n",
    "        softmaxed = F.softmax(reshaped, dim=-1)\n",
    "        processed_tensors.append(softmaxed)\n",
    "    \n",
    "    flattened_tensors = [tensor.view(tensor.shape[0], -1) for tensor in processed_tensors]\n",
    "    X_softmaxed = torch.cat(flattened_tensors, dim=1)\n",
    "    return X_softmaxed\n",
    "\n",
    "# Training loop\n",
    "# @torch.compile\n",
    "def train_loop():\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Reconstruct X_hat = B @ C\n",
    "        X_hat = torch.mm(B, C)\n",
    "        X_hat = split_and_softmax(X_hat) # this is the right inductive bias and it also dratically lowers the loss\n",
    "\n",
    "        # Compute loss only on observed entries (not masked for testing)\n",
    "        loss = torch_avg((X_hat[train_mask_tensor] - X_combined_tensor[train_mask_tensor]) ** 2, weights=loss_weights_train)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    return X_hat\n",
    "\n",
    "X_hat = train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10444820)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weights.shape\n",
    "((test_values - imputed_test_values) ** 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-rank MSE: 0.1480011874856543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After training, use X_hat to impute missing values\n",
    "X_imputed = X_hat.detach().cpu().numpy()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "imputed_test_values = X_imputed[test_mask_sparse.toarray()]\n",
    "\n",
    "mse_low_rank = np.average(((test_values - imputed_test_values) ** 2).ravel(), weights=loss_weights)\n",
    "print(f\"Low-rank MSE: {mse_low_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.1499\n",
      "Epoch [2/5], Average Loss: 0.1291\n",
      "Epoch [3/5], Average Loss: 0.1226\n",
      "Epoch [4/5], Average Loss: 0.1174\n",
      "Epoch [5/5], Average Loss: 0.1133\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "# original_mask_tensor = torch.tensor(original_mask, dtype=torch.float32)\n",
    "# test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.float32)\n",
    "\n",
    "# # Create a training mask: original data present but not in test set\n",
    "# train_mask_tensor = original_mask_tensor * (1 - test_mask_tensor)\n",
    "\n",
    "# Autoencoder architecture (same as before)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_combined_tensor.shape[1]\n",
    "encoding_dim = 64\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "# Create the autoencoder model\n",
    "model = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_combined_tensor, train_mask_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_train_mask in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        \n",
    "        # Compute loss only on non-masked, non-test values\n",
    "        loss = criterion(outputs * batch_train_mask, batch_x * batch_train_mask)\n",
    "        loss = loss / batch_train_mask.sum()  # Normalize by number of non-masked elements\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_train_mask.sum()\n",
    "    \n",
    "    avg_loss = total_loss / train_mask_tensor.sum()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder MSE: 0.13427468260616784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the trained model for imputation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imputed_data = model(X_combined_tensor)\n",
    "\n",
    "# Extract imputed values for the test set\n",
    "imputed_test_values = imputed_data[test_mask_tensor.bool()].numpy()\n",
    "true_test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "\n",
    "# Compute MSE for the autoencoder method\n",
    "mse_autoencoder = ((true_test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Autoencoder MSE: {mse_autoencoder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder without minibatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.1679\n",
      "Epoch [20/100], Loss: 0.1625\n",
      "Epoch [30/100], Loss: 0.1606\n",
      "Epoch [40/100], Loss: 0.1595\n",
      "Epoch [50/100], Loss: 0.1565\n",
      "Epoch [60/100], Loss: 0.1506\n",
      "Epoch [70/100], Loss: 0.1472\n",
      "Epoch [80/100], Loss: 0.1448\n",
      "Epoch [90/100], Loss: 0.1422\n",
      "Epoch [100/100], Loss: 0.1399\n",
      "Autoencoder MSE: 0.14354146827434908\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# # Convert data to PyTorch tensors (if not already done)\n",
    "# X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "# original_mask_tensor = torch.tensor(original_mask, dtype=torch.float32)\n",
    "# test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.float32)\n",
    "\n",
    "# # Create a training mask: original data present but not in test set\n",
    "# train_mask_tensor = original_mask_tensor * (1 - test_mask_tensor)\n",
    "\n",
    "# Autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Softmax function (same as in low-rank approximation)\n",
    "@torch.compile\n",
    "def split_and_softmax(X):\n",
    "    split_sizes = [border_indices[0]] + \\\n",
    "                [border_indices[i+1] - border_indices[i] for i in range(len(border_indices)-1)] + \\\n",
    "                [q_df.shape[1] - border_indices[-1]]\n",
    "\n",
    "    split_sizes = [item * (i+2) for i, item in enumerate(split_sizes)]\n",
    "    split_tensors = torch.split(X, split_sizes, dim=1)\n",
    "\n",
    "    processed_tensors = []\n",
    "    for i, tensor in enumerate(split_tensors):\n",
    "        options_per_question = 2 + i  # 2 for first split, 3 for second, 4 for third\n",
    "        n_questions = tensor.shape[1] // options_per_question\n",
    "        \n",
    "        # Reshape to (n_users, n_questions, options_per_question)\n",
    "        reshaped = tensor.view(-1, n_questions, options_per_question)\n",
    "        \n",
    "        # Apply softmax along the last dimension\n",
    "        softmaxed = F.softmax(reshaped, dim=-1)\n",
    "        processed_tensors.append(softmaxed)\n",
    "    \n",
    "    flattened_tensors = [tensor.view(tensor.shape[0], -1) for tensor in processed_tensors]\n",
    "    X_softmaxed = torch.cat(flattened_tensors, dim=1)\n",
    "    return X_softmaxed\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_combined_tensor.shape[1]\n",
    "encoding_dim = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 100  # Increase epochs since we're not minibatching\n",
    "\n",
    "# Create the autoencoder model\n",
    "model = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_combined_tensor)\n",
    "    outputs_softmax = split_and_softmax(outputs)\n",
    "    \n",
    "    # Compute loss only on non-masked, non-test values\n",
    "    loss = criterion(outputs_softmax * train_mask_tensor, X_combined_tensor * train_mask_tensor)\n",
    "    loss = loss / train_mask_tensor.sum()  # Normalize by number of non-masked elements\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Use the trained model for imputation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imputed_data = model(X_combined_tensor)\n",
    "    imputed_data_softmax = split_and_softmax(imputed_data)\n",
    "\n",
    "# Extract imputed values for the test set\n",
    "imputed_test_values = imputed_data_softmax[test_mask_tensor.bool()].cpu().numpy()\n",
    "true_test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "\n",
    "# Compute MSE for the autoencoder method\n",
    "mse_autoencoder = ((true_test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Autoencoder MSE: {mse_autoencoder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare MSE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/j5yw54ld78qdvpkxky67ldz40000gn/T/ipykernel_12511/1103924213.py:15: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=e_series.index, y=e_series.values, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = {\"autoencoder\": mse_autoencoder,\n",
    "'constant': mse_constant,\n",
    "'lowrank': mse_low_rank,\n",
    "'modal': mse_modal,\n",
    "'naive': mse_naive,\n",
    "'naive2': mse_naive2,\n",
    "'random': mse_random}\n",
    "\n",
    "e_series = pd.Series(errors).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=e_series.index, y=e_series.values, palette='viridis')\n",
    "plt.title('Mean Squared Error by Imputation Method')\n",
    "plt.xlabel('Imputation Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../outputs/imputers.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
