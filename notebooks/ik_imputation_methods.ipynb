{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_feather(\"../data/data.feather\")\n",
    "test_items_df = pd.read_csv(\"../data/test_items.csv\",index_col=0)\n",
    "question_data = pd.read_csv(\"../data/question_data.csv\", sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_qs = [item for item in test_items_df.index if item in raw_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = raw_df.drop(columns=test_item_qs)\n",
    "q_df = q_df.filter(regex=r'^q\\d+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the lowest response q's\n",
    "N_DROP = 2000\n",
    "low_response = [col for col in question_data.sort_values('N').iloc[:N_DROP].index if col in q_df.columns]\n",
    "q_df = q_df.drop(columns=low_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by number of categories for easier manipulation later\n",
    "sorted_num_levels = q_df.apply(lambda x: len(x.cat.categories)).sort_values()\n",
    "q_df = q_df[sorted_num_levels.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border indices where level count changes: [np.int64(252), np.int64(392)]\n",
      "Levels at borders: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique levels per column\n",
    "num_levels = q_df.nunique()\n",
    "\n",
    "# Sort columns by unique levels\n",
    "sorted_num_levels = num_levels.sort_values()\n",
    "\n",
    "# Find the indices where the level count changes\n",
    "level_counts = sorted_num_levels.values\n",
    "diff = level_counts[1:] != level_counts[:-1]\n",
    "border_indices = list(diff.nonzero()[0] + 1)  # +1 because diff is between elements\n",
    "\n",
    "# For example, print the borders and corresponding levels\n",
    "print(\"Border indices where level count changes:\", border_indices)\n",
    "print(\"Levels at borders:\", level_counts[border_indices])\n",
    "\n",
    "# You can use these indices to split the sorted columns into dfs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "non_nan = ~q_df.isna()\n",
    "non_nan_indices = np.flatnonzero(non_nan.values)\n",
    "\n",
    "np.random.seed(0)\n",
    "TEST_SIZE = 0.2\n",
    "test_size = int(len(non_nan_indices) * TEST_SIZE)\n",
    "test_mask_flat = np.random.choice(non_nan_indices, size=test_size, replace=False)\n",
    "\n",
    "test_mask = np.zeros_like(q_df.values, dtype=bool)\n",
    "test_mask.flat[test_mask_flat] = True\n",
    "\n",
    "# mask some cells that serve as our test set\n",
    "df_masked = q_df.mask(test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse_output=True, handle_unknown='ignore'), q_df.columns),\n",
    "    ],\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "def transform_and_drop(df):\n",
    "    X = preprocessor.fit_transform(df)\n",
    "\n",
    "    # the sklearn onehot encoder doesn't have an option to not encode nans\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    cols_to_keep = [i for i, name in enumerate(feature_names) if not name.endswith('_nan')]\n",
    "    X = X[:, cols_to_keep]\n",
    "    return X\n",
    "\n",
    "X_combined = transform_and_drop(df_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Original mask (shape: n_users x n_original_questions)\n",
    "\n",
    "# convert the original mask to a mask over the onehots\n",
    "def expand_mask(mask):\n",
    "    mask_expanded = []\n",
    "    for col_idx, col in enumerate(q_df.columns):\n",
    "        n_categories = len(q_df[col].cat.categories)\n",
    "        # Repeat mask along a new axis (shape: n_users x n_categories)\n",
    "        mask_repeated = np.repeat(mask[:, col_idx][:, np.newaxis], n_categories, axis=1)\n",
    "        mask_expanded.append(mask_repeated)\n",
    "        # sanity check\n",
    "        assert mask_repeated.shape[0] == 68371\n",
    "\n",
    "    # Stack horizontally (shape: n_users x n_encoded_features)\n",
    "    mask_expanded = np.hstack(mask_expanded)\n",
    "    return mask_expanded\n",
    "\n",
    "# Convert to sparse matrix (if X_combined is sparse)\n",
    "test_mask_expanded = expand_mask(test_mask)\n",
    "test_mask_sparse = sparse.csr_matrix(test_mask_expanded)\n",
    "\n",
    "original_mask = expand_mask(non_nan.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68371, 1660) (68371, 1660)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "print(test_mask_sparse.shape, X_combined.shape)\n",
    "X_combined[test_mask_sparse.nonzero()].any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaned, ready for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_q_answered = df_masked.notna().mean()\n",
    "pr_user_answered = df_masked.notna().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()\n",
    "kept_features = [item[8:].split('_') for item in feature_names if not item.endswith('_nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 q136 No\n",
      "pr(user answers)= 0.3177083333333333\n",
      "pr(question gets answered)= 0.4242588231852686\n",
      "pr(option i selected | question K gets answered)= 0.38135622435963734\n",
      "take the prodcut of these\n"
     ]
    }
   ],
   "source": [
    "# demonstration of how the naive imputation model works\n",
    "\n",
    "for user, feature in zip(*test_mask_sparse.nonzero()):\n",
    "    question, option = kept_features[feature]\n",
    "    print(user, question, option)\n",
    "    print(\"pr(user answers)=\", pr_user_answered[user])\n",
    "    print(\"pr(question gets answered)=\", pr_q_answered[question])\n",
    "    print(\"pr(option i selected | question K gets answered)=\", df_masked[question].value_counts(normalize=True)[option])\n",
    "    print(\"take the prodcut of these\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array([q for q, o in kept_features])\n",
    "options   = np.array([o for q, o in kept_features])\n",
    "\n",
    "option_probs = {\n",
    "    q: df_masked[q].value_counts(normalize=True).reindex(q_df[q].cat.categories, fill_value=0)\n",
    "    for q in q_df.columns\n",
    "}\n",
    "option_probs_df = pd.DataFrame(option_probs).T  # index: question, columns: option. super redundant but helps vectorize the operations below\n",
    "\n",
    "users_idx, features_idx = test_mask_sparse.nonzero()\n",
    "\n",
    "q_for_masked = questions[features_idx]\n",
    "o_for_masked = options[features_idx]\n",
    "\n",
    "pr_user_vals = pr_user_answered.values[users_idx]\n",
    "pr_q_vals    = pr_q_answered[q_for_masked].values\n",
    "pr_option_vals = option_probs_df.values[\n",
    "    option_probs_df.index.get_indexer(q_for_masked),\n",
    "    option_probs_df.columns.get_indexer(o_for_masked)\n",
    "]\n",
    "\n",
    "# Vectorized naive bayes\n",
    "naive_imputed_values = pr_user_vals * pr_q_vals * pr_option_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare hidden test values to real values\n",
    "X_not_masked = transform_and_drop(q_df)\n",
    "\n",
    "# check:\n",
    "X_not_masked.shape == X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2730330339564801)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_naive = (np.asarray(X_not_masked[test_mask_sparse] - naive_imputed_values).ravel()**2).mean()\n",
    "mse_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.31851035178195297)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the one that Yoram explained to me, but I think the one above makes more sense.\n",
    "\n",
    "row_mean = X_combined.mean(axis=1).ravel()\n",
    "col_mean = X_combined.mean(axis=0).ravel()\n",
    "\n",
    "naive_imputation2 = np.asarray(row_mean).ravel()[users_idx] * np.asarray(col_mean).ravel()[features_idx]\n",
    "\n",
    "mse_naive2 = (np.asarray(X_not_masked[test_mask_sparse] - naive_imputation2).ravel()**2).mean()\n",
    "mse_naive2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing values randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3334513101328833)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random\n",
    "mse_random = (np.asarray(X_not_masked[test_mask_sparse] - np.random.uniform(size=naive_imputed_values.shape)).ravel() **2).mean()\n",
    "mse_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22649856560228354)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute as as constant, mean of test data:\n",
    "\n",
    "train_data = X_not_masked[original_mask & ~test_mask_sparse.toarray()]\n",
    "mean_val = train_data.mean()\n",
    "\n",
    "mse_constant = (np.asarray(X_not_masked[test_mask_sparse] - (np.zeros_like(naive_imputed_values) + mean_val)).ravel() **2).mean()\n",
    "mse_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputing as modal answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(series):\n",
    "    return series.mode().iloc[0]\n",
    "\n",
    "df_modal_imputed = df_masked.apply(lambda col: col.fillna(get_mode(col)))\n",
    "X_modal = transform_and_drop(df_modal_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2541229049423542)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mse_modal = (np.asarray(X_not_masked[test_mask_sparse] - X_modal[test_mask_sparse]).ravel() **2).mean()\n",
    "mse_modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### low rank approximation method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0416 08:45:26.256000 12511 site-packages/torch/_logging/_internal.py:1089] [2/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.31707778573036194\n",
      "Epoch 1, Loss: 0.2988622486591339\n",
      "Epoch 2, Loss: 0.2818002998828888\n",
      "Epoch 3, Loss: 0.2666385769844055\n",
      "Epoch 4, Loss: 0.2537580728530884\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert sparse matrices to PyTorch tensors\n",
    "X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.bool)\n",
    "train_mask_tensor = torch.tensor(original_mask, dtype=torch.bool) & ~test_mask_tensor\n",
    "\n",
    "# Hyperparameters\n",
    "rank = 5  # Rank of the approximation (adjust as needed)\n",
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "# Initialize low-rank matrices B and C\n",
    "n_users, n_features = X_combined.shape\n",
    "B = torch.randn(n_users, rank, requires_grad=True)\n",
    "C = torch.randn(rank, n_features, requires_grad=True)\n",
    "X_hat = torch.mm(B, C)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([B, C], lr=learning_rate)\n",
    "\n",
    "@torch.compile\n",
    "def split_and_softmax(X):\n",
    "    split_sizes = [border_indices[0]] + \\\n",
    "                [border_indices[i+1] - border_indices[i] for i in range(len(border_indices)-1)] + \\\n",
    "                [q_df.shape[1] - border_indices[-1]]\n",
    "\n",
    "    split_sizes = [item * (i+2) for i, item in enumerate(split_sizes)]\n",
    "    split_tensors = torch.split(X, split_sizes, dim=1)\n",
    "\n",
    "    processed_tensors = []\n",
    "    for i, tensor in enumerate(split_tensors):\n",
    "        options_per_question = 2 + i  # 2 for first split, 3 for second, 4 for third\n",
    "        n_questions = tensor.shape[1] // options_per_question\n",
    "        \n",
    "        # Reshape to (n_users, n_questions, options_per_question)\n",
    "        reshaped = tensor.view(-1, n_questions, options_per_question)\n",
    "        \n",
    "        # Apply softmax along the last dimension\n",
    "        softmaxed = F.softmax(reshaped, dim=-1)\n",
    "        processed_tensors.append(softmaxed)\n",
    "    \n",
    "    flattened_tensors = [tensor.view(tensor.shape[0], -1) for tensor in processed_tensors]\n",
    "    X_softmaxed = torch.cat(flattened_tensors, dim=1)\n",
    "    return X_softmaxed\n",
    "\n",
    "# Training loop\n",
    "@torch.compile\n",
    "def train_loop():\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Reconstruct X_hat = B @ C\n",
    "        X_hat = torch.mm(B, C)\n",
    "        X_hat = split_and_softmax(X_hat) # this is the right inductive bias and it also dratically lowers the loss\n",
    "\n",
    "        # Compute loss only on observed entries (not masked for testing)\n",
    "        loss = torch.mean((X_hat[train_mask_tensor] - X_combined_tensor[train_mask_tensor]) ** 2)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "    return X_hat\n",
    "\n",
    "X_hat = train_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-rank MSE: 0.2571645045890882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After training, use X_hat to impute missing values\n",
    "X_imputed = X_hat.detach().numpy()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "imputed_test_values = X_imputed[test_mask_sparse.toarray()]\n",
    "\n",
    "mse_low_rank = ((test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Low-rank MSE: {mse_low_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.1508\n",
      "Epoch [2/5], Average Loss: 0.1304\n",
      "Epoch [3/5], Average Loss: 0.1233\n",
      "Epoch [4/5], Average Loss: 0.1183\n",
      "Epoch [5/5], Average Loss: 0.1143\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Extract imputed values for the test set\u001b[39;00m\n\u001b[32m     84\u001b[39m imputed_test_values = imputed_data[test_mask_tensor.bool()].numpy()\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m true_test_values = \u001b[43mX_not_masked\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_mask_sparse\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m()\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Compute MSE for the autoencoder method\u001b[39;00m\n\u001b[32m     88\u001b[39m mse_autoencoder = ((true_test_values - imputed_test_values) ** \u001b[32m2\u001b[39m).mean()\n",
      "\u001b[31mAttributeError\u001b[39m: 'matrix' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "original_mask_tensor = torch.tensor(original_mask, dtype=torch.float32)\n",
    "test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Create a training mask: original data present but not in test set\n",
    "train_mask_tensor = original_mask_tensor * (1 - test_mask_tensor)\n",
    "\n",
    "# Autoencoder architecture (same as before)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_combined_tensor.shape[1]\n",
    "encoding_dim = 64\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "# Create the autoencoder model\n",
    "model = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_combined_tensor, train_mask_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_train_mask in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        \n",
    "        # Compute loss only on non-masked, non-test values\n",
    "        loss = criterion(outputs * batch_train_mask, batch_x * batch_train_mask)\n",
    "        loss = loss / batch_train_mask.sum()  # Normalize by number of non-masked elements\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_train_mask.sum()\n",
    "    \n",
    "    avg_loss = total_loss / train_mask_tensor.sum()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder MSE: 0.13427468260616784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the trained model for imputation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imputed_data = model(X_combined_tensor)\n",
    "\n",
    "# Extract imputed values for the test set\n",
    "imputed_test_values = imputed_data[test_mask_tensor.bool()].numpy()\n",
    "true_test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "\n",
    "# Compute MSE for the autoencoder method\n",
    "mse_autoencoder = ((true_test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Autoencoder MSE: {mse_autoencoder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder without minibatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder MSE: 0.2129213418300474\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert data to PyTorch tensors (if not already done)\n",
    "X_combined_tensor = torch.tensor(X_combined.toarray(), dtype=torch.float32)\n",
    "original_mask_tensor = torch.tensor(original_mask, dtype=torch.float32)\n",
    "test_mask_tensor = torch.tensor(test_mask_sparse.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Create a training mask: original data present but not in test set\n",
    "train_mask_tensor = original_mask_tensor * (1 - test_mask_tensor)\n",
    "\n",
    "# Autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoding_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Softmax function (same as in low-rank approximation)\n",
    "@torch.compile\n",
    "def split_and_softmax(X):\n",
    "    split_sizes = [border_indices[0]] + \\\n",
    "                [border_indices[i+1] - border_indices[i] for i in range(len(border_indices)-1)] + \\\n",
    "                [q_df.shape[1] - border_indices[-1]]\n",
    "\n",
    "    split_sizes = [item * (i+2) for i, item in enumerate(split_sizes)]\n",
    "    split_tensors = torch.split(X, split_sizes, dim=1)\n",
    "\n",
    "    processed_tensors = []\n",
    "    for i, tensor in enumerate(split_tensors):\n",
    "        options_per_question = 2 + i  # 2 for first split, 3 for second, 4 for third\n",
    "        n_questions = tensor.shape[1] // options_per_question\n",
    "        \n",
    "        # Reshape to (n_users, n_questions, options_per_question)\n",
    "        reshaped = tensor.view(-1, n_questions, options_per_question)\n",
    "        \n",
    "        # Apply softmax along the last dimension\n",
    "        softmaxed = F.softmax(reshaped, dim=-1)\n",
    "        processed_tensors.append(softmaxed)\n",
    "    \n",
    "    flattened_tensors = [tensor.view(tensor.shape[0], -1) for tensor in processed_tensors]\n",
    "    X_softmaxed = torch.cat(flattened_tensors, dim=1)\n",
    "    return X_softmaxed\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_combined_tensor.shape[1]\n",
    "encoding_dim = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 1  # Increase epochs since we're not minibatching\n",
    "\n",
    "# Create the autoencoder model\n",
    "model = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_combined_tensor)\n",
    "    outputs_softmax = split_and_softmax(outputs)\n",
    "    \n",
    "    # Compute loss only on non-masked, non-test values\n",
    "    loss = criterion(outputs_softmax * train_mask_tensor, X_combined_tensor * train_mask_tensor)\n",
    "    loss = loss / train_mask_tensor.sum()  # Normalize by number of non-masked elements\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Use the trained model for imputation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imputed_data = model(X_combined_tensor)\n",
    "    imputed_data_softmax = split_and_softmax(imputed_data)\n",
    "\n",
    "# Extract imputed values for the test set\n",
    "imputed_test_values = imputed_data_softmax[test_mask_tensor.bool()].numpy()\n",
    "true_test_values = np.asarray(X_not_masked[test_mask_sparse])\n",
    "\n",
    "# Compute MSE for the autoencoder method\n",
    "mse_autoencoder = ((true_test_values - imputed_test_values) ** 2).mean()\n",
    "print(f\"Autoencoder MSE: {mse_autoencoder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare MSE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/j5yw54ld78qdvpkxky67ldz40000gn/T/ipykernel_12511/290987678.py:15: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=e_series.index, y=e_series.values, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = {\"autoencoder\": mse_autoencoder,\n",
    "'constant': mse_constant,\n",
    "'lowrank': mse_low_rank,\n",
    "'modal': mse_modal,\n",
    "'naive': mse_naive,\n",
    "'naive2': mse_naive2,\n",
    "'random': mse_random}\n",
    "\n",
    "e_series = pd.Series(errors).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=e_series.index, y=e_series.values, palette='viridis')\n",
    "plt.title('Mean Squared Error by Imputation Method')\n",
    "plt.xlabel('Imputation Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
